// internal/database/performance.go
package database

import (
	"context"
	"log"
	"time"

	"gorm.io/gorm"
	"gorm.io/gorm/logger"
)

// PerformanceMonitor –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
type PerformanceMonitor struct {
	db *gorm.DB
}

// NewPerformanceMonitor —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
func NewPerformanceMonitor(db *gorm.DB) *PerformanceMonitor {
	return &PerformanceMonitor{db: db}
}

// SlowQueryLogger –∫–∞—Å—Ç–æ–º–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
type SlowQueryLogger struct {
	logger.Interface
	slowThreshold time.Duration
}

// NewSlowQueryLogger —Å–æ–∑–¥–∞–µ—Ç –ª–æ–≥–≥–µ—Ä –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
func NewSlowQueryLogger(slowThreshold time.Duration) *SlowQueryLogger {
	return &SlowQueryLogger{
		Interface:     logger.Default.LogMode(logger.Info),
		slowThreshold: slowThreshold,
	}
}

// Trace –ª–æ–≥–∏—Ä—É–µ—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å –¥–µ—Ç–∞–ª—è–º–∏
func (l *SlowQueryLogger) Trace(ctx context.Context, begin time.Time, fc func() (string, int64), err error) {
	elapsed := time.Since(begin)
	
	if elapsed >= l.slowThreshold {
		sql, rows := fc()
		log.Printf("üêå SLOW QUERY [%v] [rows:%v] %s", elapsed, rows, sql)
		
		// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
		if elapsed >= 5*time.Second {
			log.Printf("üî• VERY SLOW QUERY: Consider optimization for: %s", sql)
		}
	}
}

// EnableSlowQueryLogging –≤–∫–ª—é—á–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
func EnableSlowQueryLogging(db *gorm.DB, threshold time.Duration) {
	db.Logger = NewSlowQueryLogger(threshold)
}

// GetDatabaseStats –ø–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
func (pm *PerformanceMonitor) GetDatabaseStats() map[string]interface{} {
	stats := make(map[string]interface{})
	
	// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
	sqlDB, err := pm.db.DB()
	if err == nil {
		dbStats := sqlDB.Stats()
		stats["open_connections"] = dbStats.OpenConnections
		stats["in_use"] = dbStats.InUse
		stats["idle"] = dbStats.Idle
		// stats["max_open_connections"] = dbStats.MaxOpenConns
		// stats["max_idle_connections"] = dbStats.MaxIdleConns
	}
	
	// –†–∞–∑–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü
	tableSizes := pm.getTableSizes()
	if len(tableSizes) > 0 {
		stats["table_sizes"] = tableSizes
	}
	
	// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤
	indexStats := pm.getIndexStats()
	if len(indexStats) > 0 {
		stats["index_usage"] = indexStats
	}
	
	return stats
}

// getTableSizes –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
func (pm *PerformanceMonitor) getTableSizes() map[string]int64 {
	sizes := make(map[string]int64)
	tables := []string{"users", "chat_sessions", "chat_messages", "properties", "parse_requests"}
	
	for _, table := range tables {
		var count int64
		if err := pm.db.Table(table).Count(&count).Error; err == nil {
			sizes[table] = count
		}
	}
	
	return sizes
}

// getIndexStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤
func (pm *PerformanceMonitor) getIndexStats() []map[string]interface{} {
	var stats []map[string]interface{}
	
	// –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω–¥–µ–∫—Å–æ–≤ (PostgreSQL)
	rows, err := pm.db.Raw(`
		SELECT 
			schemaname,
			tablename,
			indexname,
			idx_scan as scans,
			idx_tup_read as tuples_read,
			idx_tup_fetch as tuples_fetched
		FROM pg_stat_user_indexes 
		WHERE idx_scan > 0 
		ORDER BY idx_scan DESC 
		LIMIT 10
	`).Rows()
	
	if err != nil {
		return stats
	}
	defer rows.Close()
	
	for rows.Next() {
		var schema, table, index string
		var scans, tuplesRead, tuplesFetched int64
		
		if err := rows.Scan(&schema, &table, &index, &scans, &tuplesRead, &tuplesFetched); err == nil {
			stats = append(stats, map[string]interface{}{
				"schema":          schema,
				"table":           table,
				"index":           index,
				"scans":           scans,
				"tuples_read":     tuplesRead,
				"tuples_fetched":  tuplesFetched,
			})
		}
	}
	
	return stats
}

// OptimizeDatabase –≤—ã–ø–æ–ª–Ω—è–µ—Ç –±–∞–∑–æ–≤—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
func (pm *PerformanceMonitor) OptimizeDatabase() error {
	log.Println("üîß Starting database optimization...")
	
	// –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
	if err := pm.db.Exec("ANALYZE").Error; err != nil {
		log.Printf("Failed to analyze database: %v", err)
		return err
	}
	
	// –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º –∏–Ω–¥–µ–∫—Å–∞–º
	unusedIndexes := pm.findUnusedIndexes()
	if len(unusedIndexes) > 0 {
		log.Printf("üìä Found %d potentially unused indexes:", len(unusedIndexes))
		for _, index := range unusedIndexes {
			log.Printf("   - %s.%s (scans: %d)", index["table"], index["index"], index["scans"])
		}
	}
	
	log.Println("‚úÖ Database optimization completed")
	return nil
}

// findUnusedIndexes –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã
func (pm *PerformanceMonitor) findUnusedIndexes() []map[string]interface{} {
	var indexes []map[string]interface{}
	
	rows, err := pm.db.Raw(`
		SELECT 
			schemaname,
			tablename,
			indexname,
			idx_scan as scans
		FROM pg_stat_user_indexes 
		WHERE idx_scan < 10  -- –ú–µ–Ω–µ–µ 10 —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–π –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∏–Ω–¥–µ–∫—Å
		AND indexname NOT LIKE '%_pkey'  -- –ò—Å–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤–∏—á–Ω—ã–µ –∫–ª—é—á–∏
		ORDER BY idx_scan ASC
	`).Rows()
	
	if err != nil {
		return indexes
	}
	defer rows.Close()
	
	for rows.Next() {
		var schema, table, index string
		var scans int64
		
		if err := rows.Scan(&schema, &table, &index, &scans); err == nil {
			indexes = append(indexes, map[string]interface{}{
				"schema": schema,
				"table":  table,
				"index":  index,
				"scans":  scans,
			})
		}
	}
	
	return indexes
}

// LogDatabaseHealth –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–¥–æ—Ä–æ–≤—å–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
func (pm *PerformanceMonitor) LogDatabaseHealth() {
	stats := pm.GetDatabaseStats()
	
	log.Println("üìä Database Health Report:")
	
	if connections, ok := stats["open_connections"]; ok {
		log.Printf("   Connections: %v open, %v in use, %v idle", 
			connections, stats["in_use"], stats["idle"])
	}
	
	if sizes, ok := stats["table_sizes"].(map[string]int64); ok {
		log.Printf("   Table sizes:")
		for table, count := range sizes {
			log.Printf("     - %s: %d rows", table, count)
		}
	}
}